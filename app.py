import streamlit as st
import firebase_admin
from firebase_admin import credentials, firestore
import pandas as pd
import plotly.express as px
import os
from datetime import datetime, timedelta
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import ast


# --- 1. åˆå§‹åŒ– Firebase (åªåŸ·è¡Œä¸€æ¬¡) ---
# Streamlit æœƒåœ¨æ¯æ¬¡äº’å‹•æ™‚é‡è·‘æ•´å€‹è…³æœ¬ï¼Œæ‰€ä»¥è¦æª¢æŸ¥æ˜¯å¦å·²ç¶“åˆå§‹åŒ–
if not firebase_admin._apps:
    # 1. å„ªå…ˆå˜—è©¦å¾ž Streamlit Secrets è®€å– (é›²ç«¯æ¨¡å¼)
    if "firebase" in st.secrets:
        # é€™è£¡çš„ "firebase" å°æ‡‰åˆ° Secrets è£¡é¢çš„ [firebase]
        key_dict = dict(st.secrets["firebase"])
        
        if "\\n" in key_dict["private_key"]:
            key_dict["private_key"] = key_dict["private_key"].replace("\\n", "\n")
        
        cred = credentials.Certificate(key_dict)
    
    # 2. å¦‚æžœæ²’æœ‰ç’°å¢ƒè®Šæ•¸ï¼Œå‰‡å˜—è©¦è®€å–æœ¬åœ°æª”æ¡ˆ (çµ¦ä½ è‡ªå·±é–‹ç™¼ç”¨)
    elif os.path.exists("serviceAccountKey.json"):
        cred = credentials.Certificate("serviceAccountKey.json")
    
    else:
        st.error("æ‰¾ä¸åˆ° Firebase é‡‘é‘°ï¼")
        st.stop()

    firebase_admin.initialize_app(cred)

db = firestore.client()

# --- 2. è³‡æ–™è®€å–èˆ‡å¿«å– (Cache) ---
# ä½¿ç”¨ @st.cache_data é¿å…æ¯æ¬¡æŒ‰æŒ‰éˆ•éƒ½é‡æ–°åŽ» Firebase æ’ˆè³‡æ–™ (çœæµé‡ã€åŠ é€Ÿ)
@st.cache_data(ttl=600) 
def load_hybrid_data():
    """
    1. è®€å– GitHub ä¸Šçš„ CSV (æ­·å²è³‡æ–™)
    2. è®€å– Firebase (æœ€æ–°è³‡æ–™)
    3. åˆä½µå›žå‚³
    """
    # --- Part A: è®€å–æ­·å² CSV (æœ¬åœ°æª”æ¡ˆ) ---
    csv_file = "news_history.csv"
    
    if os.path.exists(csv_file):
        try:
            history_df = pd.read_csv(csv_file)
            # ç¢ºä¿æ—¥æœŸæ¬„ä½æ˜¯ datetime ç‰©ä»¶ï¼Œæ–¹ä¾¿å¾Œé¢æ¯”è¼ƒ
            history_df['date_obj'] = pd.to_datetime(history_df['date_str'])
            last_date_in_csv = history_df['date_str'].max()
            print(f"ðŸ“‚ [CSV] è¼‰å…¥æ­·å²è³‡æ–™: {len(history_df)} ç­† (æ›´æ–°è‡³ {last_date_in_csv})")
        except Exception as e:
            print(f"âŒ è®€å– CSV å¤±æ•—: {e}")
            history_df = pd.DataFrame()
            last_date_in_csv = "2025-11-01" # é è¨­èµ·é»ž
    else:
        print("âš ï¸ æ‰¾ä¸åˆ° CSV æª”æ¡ˆï¼Œå°‡åªæŠ“å– Firebase è³‡æ–™")
        history_df = pd.DataFrame()
        last_date_in_csv = "2025-11-01"

    # --- Part B: æŠ“å– Firebase æ–°è³‡æ–™ ---
    # åªæŠ“ CSV æœ€å¾Œä¸€å¤© "ä¹‹å¾Œ" çš„è³‡æ–™
    print(f"ðŸ“¡ [Firebase] æ­£åœ¨æª¢æŸ¥ {last_date_in_csv} ä¹‹å¾Œçš„æ–°èž...")
    
    try:
        docs = (
            db.collection("news")
            .where("date_str", ">", last_date_in_csv)
            .stream()
        )
        new_data = [doc.to_dict() for doc in docs]
        print(f"âœ… [Firebase] æŠ“åˆ°æ–°è³‡æ–™: {len(new_data)} ç­†")
    except Exception as e:
        print(f"âŒ Firebase è®€å–éŒ¯èª¤: {e}")
        new_data = []

    # --- Part C: åˆä½µ ---
    if new_data:
        new_df = pd.DataFrame(new_data)
        new_df['date_obj'] = pd.to_datetime(new_df['date_str'])
        
        # æŠŠèˆŠçš„è·Ÿæ–°çš„æŽ¥èµ·ä¾†
        if not history_df.empty:
            full_df = pd.concat([history_df, new_df], ignore_index=True)
        else:
            full_df = new_df
            
        # é›™é‡ä¿éšªï¼šä¾é€£çµåŽ»é‡è¤‡ (é˜²æ­¢ CSV è·Ÿ Firebase é‡ç–Š)
        full_df = full_df.drop_duplicates(subset=['link'], keep='last')
        return full_df
    else:
        return history_df

# --- 3. ä»‹é¢é–‹å§‹ ---
st.set_page_config(
    page_title="ETtoday æ–°èžè¼¿æƒ…æˆ°æƒ…å®¤",
    page_icon="ðŸ“°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# === æ¨™é¡Œèˆ‡ç°¡ä»‹ ===
st.title("ðŸ“° ETtoday æ–°èžè¼¿æƒ…æˆ°æƒ…å®¤")
st.markdown("---")

# ==========================================
# 1. å´é‚Šæ¬„ Part Aï¼šæ—¥æœŸé¸æ“‡
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ ç¯©é¸æŽ§åˆ¶")
    
    # è¨­å®šé è¨­å€¼
    default_start = datetime.now().date() - timedelta(days=7)
    default_end = datetime.now().date()

    # æ—¥æœŸé¸æ“‡å™¨
    date_range = st.date_input(
        "ðŸ“… é¸æ“‡è³‡æ–™æ—¥æœŸå€é–“", 
        (default_start, default_end), 
        max_value=datetime.now().date()
    )

    if len(date_range) == 2:
        start_date, end_date = date_range
        
        days_diff = (end_date - start_date).days
    else:
        st.info("è«‹é¸æ“‡çµæŸæ—¥æœŸ")
        st.stop() # é€™è£¡åœä½ï¼Œç­‰å¾…ä½¿ç”¨è€…é¸å®Œæ—¥æœŸ

# ==========================================
# 2. æ ¸å¿ƒå‹•ä½œï¼šè¼‰å…¥è³‡æ–™
# ==========================================
# æ­¥é©Ÿ 1: å…ˆæ‹¿åˆ° "å®Œæ•´è³‡æ–™åº«" (é€™æ­¥æœ‰å¿«å–ä¿è­·)
full_df = load_hybrid_data()

# æ­¥é©Ÿ 2: æ ¹æ“šä½¿ç”¨è€…é¸çš„æ—¥æœŸï¼Œåœ¨ "è¨˜æ†¶é«”ä¸­" åˆ‡å‰²è³‡æ–™
if not full_df.empty:
    # é€™è£¡è¦åšæ—¥æœŸéŽæ¿¾ï¼Œå› ç‚º load_hybrid_data ç¾åœ¨å›žå‚³çš„æ˜¯å¾ž 11æœˆ è‡³ä»Šçš„æ‰€æœ‰è³‡æ–™
    # æˆ‘å€‘è¦æŠŠ start_date, end_date è½‰æˆ datetime æ‰èƒ½è·Ÿ date_obj æ¯”è¼ƒ
    mask = (full_df['date_obj'].dt.date >= start_date) & (full_df['date_obj'].dt.date <= end_date)
    df = full_df[mask]
else:
    df = pd.DataFrame()

# é˜²å‘†ï¼šå¦‚æžœ df æ˜¯ç©ºçš„
if df.empty:
    st.warning(f"âš ï¸ åœ¨ {start_date} åˆ° {end_date} ä¹‹é–“æ‰¾ä¸åˆ°æ–°èžè³‡æ–™ã€‚")
    st.stop()
# ==========================================
# 3. å´é‚Šæ¬„ Part Bï¼šé¡žåˆ¥èˆ‡è¨˜è€…ç¯©é¸
# ==========================================
with st.sidebar:
    # --- é¡žåˆ¥ç¯©é¸ ---
    st.write("---")
    st.write("ðŸ·ï¸ æ–°èžé¡žåˆ¥ç¯©é¸")
    
    all_categories = sorted(df['category'].unique())
    
    if "selected_cats" not in st.session_state:
        st.session_state["selected_cats"] = all_categories

    def select_all():
        st.session_state["selected_cats"] = all_categories

    def deselect_all():
        st.session_state["selected_cats"] = []

    col1, col2 = st.columns(2)
    with col1:
        st.button("âœ… å…¨é¸", on_click=select_all, use_container_width=True)
    with col2:
        st.button("âŒ æ¸…ç©º", on_click=deselect_all, use_container_width=True)

    selected_cats = st.multiselect(
        "è«‹é¸æ“‡é¡žåˆ¥ï¼š",
        options=all_categories,
        key="selected_cats"
    )
    
    # --- è¨˜è€…ç¯©é¸ ---
    st.write("---")
    st.write("ðŸŽ¤ è¨˜è€…ç¯©é¸")
    
    all_reporters = sorted(df['reporter'].astype(str).unique())
    
    selected_reporters = st.multiselect(
        "æœå°‹æˆ–é¸æ“‡è¨˜è€… (ç•™ç©ºå³é¡¯ç¤ºå…¨éƒ¨)ï¼š",
        options=all_reporters,
        default=[]
    )
    
    # --- è¨ˆç®—éŽæ¿¾å¾Œçš„çµæžœ (çµ¦ Metric ä½¿ç”¨) ---
    mask = df['category'].isin(selected_cats)
    
    if selected_reporters:
        mask = mask & (df['reporter'].isin(selected_reporters))
            
    filtered_count = df[mask].shape[0]
    total_count = df.shape[0]

    # --- é¡¯ç¤ºæŒ‡æ¨™å¡ ---
    st.markdown("---")
    st.metric(
        label="ðŸ“Š è³‡æ–™ç­†æ•¸ç‹€æ…‹",
        value=f"{filtered_count} ç­†",
        delta=f"æœ¬å€é–“ç¸½åº«å­˜: {total_count} ç­†",
        delta_color="off"
    )
    st.caption("è³‡æ–™ä¾†æºï¼šETtoday")

# ==========================================
# 4. ä¸»ç•«é¢è³‡æ–™éŽæ¿¾ (ç”¢ç”Ÿå…¨åŸŸ filtered_df çµ¦åœ–è¡¨ç”¨)
# ==========================================
mask = df['category'].isin(selected_cats)

if selected_reporters:
    mask = mask & (df['reporter'].isin(selected_reporters))

filtered_df = df[mask]

# === é—œéµæŒ‡æ¨™å€ (KPI Metrics) ===
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("ç¸½æ–‡ç« æ•¸", f"{len(filtered_df)} ç¯‡")
with col2:
    # ç®—å‡ºæœ€æ´»èºè¨˜è€…
    valid_reporters = filtered_df[filtered_df['reporter'] != 'Unknown']

    if not valid_reporters.empty:
        top_reporter = valid_reporters['reporter'].mode()[0]
    else:
        top_reporter = "N/A"
    st.metric("ðŸ”¥ æœ€æ´»èºè¨˜è€…", top_reporter)
with col3:
    st.metric("æ¶µè“‹é¡žåˆ¥æ•¸", f"{filtered_df['category'].nunique()} é¡ž")
with col4:
    st.metric("â­ é—œéµè©žç„¦é»ž", "è«‹çœ‹ä¸‹æ–¹åˆ†æž")

st.markdown("---")

# === ä¸»å…§å®¹åˆ†é  ===
tab1, tab2, tab3, tab4 = st.tabs(["ðŸ“ˆ è¶¨å‹¢ç¸½è¦½", "â˜ï¸ é—œéµè©žé›²", "ðŸ† è¨˜è€…æˆ°åŠ›æ¦œ", "ðŸ“Š æˆ°åŠ›åˆ†æžèˆ‡è³‡æ–™åº«"])

with tab1:
    col_a, col_b = st.columns([2, 1])
    with col_a:
        st.subheader("å„é¡žåˆ¥æ–°èžæ•¸é‡ä½”æ¯”")
        cat_counts = filtered_df['category'].value_counts().reset_index()
        cat_counts.columns = ['é¡žåˆ¥', 'æ•¸é‡']
        fig_pie = px.pie(cat_counts, values='æ•¸é‡', names='é¡žåˆ¥', hole=0.4) # ç”œç”œåœˆåœ–æ¯”è¼ƒæ½®
        st.plotly_chart(fig_pie, use_container_width=True)
    with col_b:
        st.subheader("æ¯æ—¥æ–‡ç« é‡è¶¨å‹¢")
        # ä¾æ—¥æœŸåˆ†çµ„çµ±è¨ˆ
        daily_counts = filtered_df.groupby(filtered_df['date_obj'].dt.date).size().reset_index(name='æ–‡ç« æ•¸')
        fig_line = px.line(daily_counts, x='date_obj', y='æ–‡ç« æ•¸', markers=True)
        st.plotly_chart(fig_line, use_container_width=True)

with tab2:
    st.subheader("ç†±é–€é—œéµè©žæ–‡å­—é›²")
    # é€™è£¡éœ€è¦æŠŠæ‰€æœ‰ keywords ä¸²æŽ¥èµ·ä¾†
    all_words = []
    if 'keywords' in filtered_df.columns:
        for k in filtered_df['keywords']:
            if k is None:
                continue
                
            # ç‹€æ³ 1: å®ƒæ˜¯ list (å¾ž Firebase ç›´æŽ¥ä¾†)
            if isinstance(k, list):
                all_words.extend(k)
                
            # ç‹€æ³ 2: å®ƒæ˜¯ string (å¾ž CSV è®€å–ï¼Œæ ¼å¼åƒ "['a', 'b']")
            elif isinstance(k, str):
                try:
                    # å˜—è©¦è§£æžå­—ä¸²åˆ—è¡¨
                    parsed = ast.literal_eval(k)
                    if isinstance(parsed, list):
                        all_words.extend(parsed)
                    else:
                        all_words.append(k) # è§£æžå‡ºä¾†ä¸æ˜¯ listï¼Œå°±ç•¶å–®å­—
                except:
                    # è§£æžå¤±æ•—ï¼Œå°±ç›´æŽ¥ç•¶ä½œä¸€å€‹å–®å­—
                    all_words.append(k)
    else:
        st.error("è³‡æ–™ä¸­æ‰¾ä¸åˆ° 'keywords' æ¬„ä½ï¼Œè«‹æª¢æŸ¥çˆ¬èŸ²è³‡æ–™")
        
    if all_words:
        text = " ".join(all_words)
        
        # è¨­å®šå­—åž‹æª”å
        font_path = "NotoSansTC-VariableFont_wght.ttf" 
        
        import os
        if not os.path.exists(font_path):
            st.warning("âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ°ä¸­æ–‡å­—åž‹æª”ï¼Œæ–‡å­—é›²å¯èƒ½é¡¯ç¤ºç‚ºæ–¹å¡Šã€‚è«‹ä¸Šå‚³ .otf/.ttf æª”æ¡ˆã€‚")
            use_font = None # ä½¿ç”¨é è¨­
        else:
            use_font = font_path

        # å»ºç«‹æ–‡å­—é›²ç‰©ä»¶ï¼Œä¸¦æŒ‡å®š font_path
        wc = WordCloud(
            font_path=use_font,
            width=1200, 
            height=800, 
            background_color="black",

            max_words=200,
            colormap='viridis',
            prefer_horizontal=0.9,
            relative_scaling=0.5,

            margin=10,
        ).generate(text)

        # ç•«åœ–
        fig, ax = plt.subplots()
        ax.imshow(wc, interpolation='bilinear')
        ax.axis("off")
        st.pyplot(fig)
    else:
        st.info("ç„¡é—œéµè©žè³‡æ–™")

with tab3:
    st.subheader("è¨˜è€…ç”¢é‡ Top 20")
    reporter_counts = filtered_df['reporter'].value_counts().head(20).reset_index()
    reporter_counts.columns = ['è¨˜è€…', 'æ–‡ç« æ•¸']
    reporter_counts = reporter_counts[reporter_counts['è¨˜è€…'] != 'Unknown']
    
    fig_bar = px.bar(reporter_counts, x='æ–‡ç« æ•¸', y='è¨˜è€…', orientation='h', color='æ–‡ç« æ•¸')
    fig_bar.update_layout(yaxis={'categoryorder':'total ascending'}) # è®“é•·æ¢åœ–ç”±å¤§æŽ’åˆ°å°
    st.plotly_chart(fig_bar, use_container_width=True)

with tab4:
    # å¦‚æžœä½¿ç”¨è€…æœ‰é¸è¨˜è€…ï¼Œæ‰é¡¯ç¤ºè©³ç´°åˆ†æž
    if selected_reporters:
        st.subheader(f"ðŸ“Š è¨˜è€…æˆ°åŠ›åˆ†æžï¼š{'ã€'.join(selected_reporters)}")
        
        if not filtered_df.empty:
            sub_t1, sub_t2 = st.tabs(["ðŸ“Š é ˜åŸŸåˆ†å¸ƒ", "ðŸ“ˆ ç™¼æ–‡è¶¨å‹¢"])
            
            with sub_t1:
                reporter_stats = filtered_df.groupby(['reporter', 'category']).size().reset_index(name='count')
                fig_cat = px.bar(
                    reporter_stats, x="reporter", y="count", color="category",
                    title="ç™¼ç¨¿é ˜åŸŸåˆ†å¸ƒ", text="count",
                    labels={"reporter": "è¨˜è€…", "count": "ç¯‡æ•¸", "category": "é¡žåˆ¥"}
                )
                st.plotly_chart(fig_cat, use_container_width=True)

            with sub_t2:
                daily_stats = filtered_df.groupby([filtered_df['date_obj'].dt.date, 'reporter']).size().reset_index(name='count')
                daily_stats.columns = ['date', 'reporter', 'count']
                fig_trend = px.line(
                    daily_stats, x='date', y='count', color='reporter', markers=True,
                    title="æ¯æ—¥ç™¼æ–‡æ•¸é‡èµ°å‹¢",
                    labels={"date": "æ—¥æœŸ", "count": "ç¯‡æ•¸", "reporter": "è¨˜è€…"}
                )
                st.plotly_chart(fig_trend, use_container_width=True)
            
            st.markdown("---")
        else:
            st.warning("âš ï¸ è©²è¨˜è€…åœ¨æ­¤ç¯©é¸æ¢ä»¶ä¸‹ç„¡ç™¼æ–‡ç´€éŒ„ã€‚")

    st.subheader(f"ðŸ“ è©³ç´°æ–‡ç« åˆ—è¡¨ (å…± {len(filtered_df)} ç­†)")
    
    st.dataframe(
        filtered_df[['date_str', 'category', 'reporter', 'title', 'link']],
        column_config={
            "link": st.column_config.LinkColumn("é–±è®€å…¨æ–‡", display_text="é»žæ“Šå‰å¾€"),
            "date_str": "ç™¼å¸ƒæ™‚é–“",
            "category": "åˆ†é¡ž",
            "reporter": "è¨˜è€…",
            "title": "æ¨™é¡Œ"
        },
        use_container_width=True,
        hide_index=True
    )