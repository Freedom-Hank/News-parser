import pandas as pd
import re
import json
import os
import jieba
import jieba.analyse

INPUT_FILE = "ettoday_raw_data.csv"
OUTPUT_JSON = "cleaned_news.json"

# --- é—œéµä¿®æ­£ï¼šå®šç¾©ã€Œåƒåœ¾è©ã€é»‘åå–® ---
# é€™äº›è©é›–ç„¶å‡ºç¾é »ç‡é«˜ï¼Œä½†å°åˆ†ææ²’å¹«åŠ©ï¼Œæˆ‘å€‘è¦æŠŠå®ƒå€‘éæ¿¾æ‰
STOP_WORDS = {
    "è¨˜è€…", "å ±å°", "ç¿»æ”", "åœ–æ–‡", "æ¡è¨ª", "ç¶œåˆ", "ä¸­å¿ƒ", "ç·¨è¼¯", 
    "ä¾†æº", "ç•«é¢", "æ›å…‰", "æŒ‡å‡º", "è¡¨ç¤º", "èªç‚º", "ä»Šæ—¥", "æ˜¨æ—¥",
    "å°ç£", "å°åŒ—", "ETtoday", "æ–°èé›²", "å¯ä»¥", "æˆ‘å€‘", "æ‡‰è©²"
}

def extract_keywords_from_text(text):
    if not text or pd.isna(text):
        return []
    
    # æ“´å¤§å€™é¸ç¯„åœåˆ° 20 å€‹ï¼Œå› ç‚ºæˆ‘å€‘æœƒéæ¿¾æ‰å¾ˆå¤šæ±è¥¿
    raw_keywords = jieba.analyse.extract_tags(text, topK=20)
    
    filtered_keywords = []
    for w in raw_keywords:
        # --- éæ¿¾é‚è¼¯ ---
        # 1. å¿…é ˆä¸åœ¨é»‘åå–®
        # 2. é•·åº¦ > 1 (éæ¿¾å–®å­—)
        # 3. ä¸èƒ½æ˜¯ç´”æ•¸å­— (æ–°å¢åŠŸèƒ½ï¼Œéæ¿¾ "20", "10")
        if w not in STOP_WORDS and len(w) > 1 and not w.isdigit():
            filtered_keywords.append(w)
    
    return filtered_keywords[:5] # æœ€å¾Œåªå–å‰ 5 å€‹

def extract_reporter(content):
    if pd.isna(content): return "Unknown"
    patterns = [
        r"è¨˜è€…(.*?)[ï¼|/]", 
        r"æ–‡[ï¼|/](.*?)[\s|ï¼Œ|ã€‚]",
        r"åœ–ã€æ–‡[ï¼|/](.*?)\)",
    ]
    for pattern in patterns:
        match = re.search(pattern, content)
        if match:
            name = match.group(1).strip()
            # æ’é™¤æ˜é¡¯éŒ¯èª¤çš„çµæœ
            if len(name) > 5 or any(x in name for x in ["ä¸­å¿ƒ", "å ±å°", "ç¶œåˆ"]): 
                continue
            return name
    return "Unknown"

def clean_data():
    print(f"ğŸ§¹ é–‹å§‹è®€å– raw data: {INPUT_FILE}")
    if not os.path.exists(INPUT_FILE):
        print("âŒ æ‰¾ä¸åˆ° raw dataï¼Œè«‹å…ˆåŸ·è¡Œçˆ¬èŸ²ï¼")
        return

    df = pd.read_csv(INPUT_FILE)
    df.drop_duplicates(subset=['link'], inplace=True)
    df.dropna(subset=['title', 'content'], inplace=True)
    
    print("ğŸ” æ­£åœ¨æå–è³‡æ–™ (è¨˜è€… & é—œéµè©)...")
    
    df['reporter'] = df['content'].apply(extract_reporter)

    print("ğŸ” æ­£åœ¨å¾ã€Œæ¨™é¡Œã€æå–é—œéµè©...")
    
    df['keywords'] = df['title'].apply(extract_keywords_from_text)
    
    final_df = df[['title', 'content', 'date_str', 'category', 'reporter', 'link', 'keywords']]
    
    json_data = final_df.to_dict(orient='records')
    
    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
        json.dump(json_data, f, ensure_ascii=False, indent=4)
        
    print(f"âœ¨ æ¸…æ´—å®Œæˆï¼æª”æ¡ˆå·²å­˜ç‚º: {OUTPUT_JSON}")
    # é è¦½ä¸€ä¸‹ï¼Œç¢ºèªã€Œè¨˜è€…ã€é€™ç¨®è©æœ‰æ²’æœ‰æ¶ˆå¤±
    print("ğŸ‘€ é—œéµè©ç¯„ä¾‹:", final_df.iloc[0]['keywords'])

if __name__ == "__main__":
    clean_data()