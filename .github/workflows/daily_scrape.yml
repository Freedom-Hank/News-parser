name: Daily News Scraper

on:
  schedule:
    # GitHub 使用 UTC 時間，台灣是 UTC+8
    # 所以設定 UTC 22:00 = 台灣早上 06:00
    - cron: '0 */6 * * *'
  # 允許你手動按按鈕觸發 (方便測試)
  workflow_dispatch:

jobs:
  try-ubuntu:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code (下載程式碼)
        uses: actions/checkout@v4

      - name: Set up Python (安裝 Python)
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies (安裝套件)
        run: |
          pip install -r requirements.txt

      - name: Create Firebase Key File (產生金鑰檔案)
        env:
          FIREBASE_CREDENTIALS: ${{ secrets.FIREBASE_CREDENTIALS }}
        run: echo "$FIREBASE_CREDENTIALS" > serviceAccountKey.json

      - name: Run Pipeline (爬蟲 -> 清洗 -> 上傳)
        run: |
          python News_crawler.py
          python News_cleaner.py
          python News_uploader.py

# === 第二棒：備援 Windows (只有在 Ubuntu 失敗時才會跑) ===
  fallback-windows:
    needs: try-ubuntu
    if: failure()
    runs-on: windows-latest

    steps:
      - name: Checkout code (下載程式碼)
        uses: actions/checkout@v4

      - name: Set up Python (安裝 Python)
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies (安裝套件)
        run: |
          pip install -r requirements.txt

      - name: Create Firebase Key File (產生金鑰檔案)
        shell: pwsh
        env:
          FIREBASE_CREDENTIALS: ${{ secrets.FIREBASE_CREDENTIALS }}
        run: $env:FIREBASE_CREDENTIALS | Out-File -FilePath serviceAccountKey.json -Encoding utf8

      - name: Run Pipeline (爬蟲 -> 清洗 -> 上傳)
        run: |
          python News_crawler.py
          python News_cleaner.py
          python News_uploader.py
